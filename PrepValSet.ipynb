{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0a7edc29559242b93c8de2387354c06a79d5855a6429ad88e5f2d592a2c3647cd",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# Additional pandas settings\n",
    "pd.set_option('max_row', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Users/aakritigupta/Desktop/Hackathon 2021/CSV Files'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Set the working directory\n",
    "os.chdir('/Users/aakritigupta/Desktop/Hackathon 2021/CSV Files')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in the data and clean it up \n",
    "def readData(csvFile):\n",
    "  # Read in dataset\n",
    "  df = pd.read_csv(csvFile)\n",
    "\n",
    "  # Extract YEAR out of column and store in new column\n",
    "  df.SERIALNO = df.SERIALNO.map(str)\n",
    "  df['YEAR'] = df.SERIALNO.str[:4]\n",
    "\n",
    "  # Convert YEAR to datetime object and filter dataset to only keep 2016 and 2017 data\n",
    "  df['YEAR'] = pd.to_datetime(df['YEAR']).dt.year\n",
    "  df2 = df[(df['YEAR'] == 2017)]\n",
    "  \n",
    "  return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop unnecessary columns\n",
    "def dropCols(df):\n",
    "  # Create a list of all columns that need to be dropped\n",
    "  drop_cols = []\n",
    "\n",
    "  # Add person weight indicators to the list\n",
    "  for i in df.columns:\n",
    "    if ('PWGTP' in i) & (len(i) >= 6) or  (i[0]=='F'):\n",
    "      drop_cols.append(i)\n",
    "\n",
    "  # Add the specific columns identified after walking through the dataset manually\n",
    "  drop_cols.extend(['SERIALNO','POBP','RT','DIVISION','SPORDER','PUMA','RELSHIPP','ANC','ANC1P','ANC2P','QTRBIR','RAC2P','RAC3P','OC','RC','ENG','JWRIP','MARHYP','WKWN','YOEP','DECADE','DRIVESP',\"JWAP\",\"JWDP\",'LANP','NAICSP','MIGPUMA','MIGSP','MSP','NOP','PAOC','POWPUMA','POWSP','SCIENGP','SCIENGRLP','SOCP','VPS','CITWP'])\n",
    "\n",
    "  # Drop all columns from the dataframe\n",
    "  df2 = df.drop(columns=drop_cols)\n",
    "\n",
    "  # Drop duplicate rows\n",
    "  df3 = df2.drop_duplicates()\n",
    "\n",
    "  return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to impute missing values - Numerical and Categorical features\n",
    "def missingVals(df):\n",
    "  # Create a list of numerical columns\n",
    "  Numerical = ['PWGTP','AGEP','INTP','JWMNP','OIP','PAP','RETP','SEMP','SSIP','SSP','WAGP','WKHP','INDP','PERNP','PINCP','POVPIP']\n",
    "\n",
    "  # For all missing values in that list, replace with the mean of the column\n",
    "  for i in Numerical:\n",
    "    df[i].fillna((df[i].mean()), inplace=True)\n",
    "  \n",
    "  # Create a list of categorical columns\n",
    "  Categorical = []\n",
    "\n",
    "  # For all missing values in categorical columns, enter category NoInput and convert dtype\n",
    "  for j in df.columns:\n",
    "    if j not in Numerical:\n",
    "      df[j].fillna('NoInput', inplace=True)\n",
    "      df[j] = df[j].astype('category')\n",
    "      Categorical.append(j)\n",
    "  \n",
    "  return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode categorical variables\n",
    "# def oheCat(df, fileNum):\n",
    "def oheCat(df):\n",
    "  # Extract the year column from the dataframe\n",
    "  date = df['YEAR']\n",
    "  state = df['ST']\n",
    "\n",
    "  # Drop the year column from the dataframe for encoding purposes\n",
    "  df2 = df.drop(columns=['YEAR', 'ST'])\n",
    "\n",
    "  # Create a list of all identified numerical variables\n",
    "  Numerical = ['PWGTP','AGEP','INTP','JWMNP','OIP','PAP','RETP','SEMP','SSIP','SSP','WAGP','WKHP','INDP','PERNP','PINCP','POVPIP']\n",
    "\n",
    "  # Create a list of all categorical columns\n",
    "  cat = []\n",
    "  for i in df2.columns:\n",
    "    if (i not in Numerical):\n",
    "      cat.append(i)\n",
    "  \n",
    "  # One hot encode all of the categorical variables\n",
    "  df3 = pd.get_dummies(df2, prefix=cat)\n",
    "\n",
    "  # Add the YEAR column back into the dataset\n",
    "  df3['YEAR'] = date\n",
    "  df3['ST'] = state\n",
    "\n",
    "  # Write the final dataset back to the Google Drive folder\n",
    "  # filePath = \"/content/gdrive/MyDrive/Hackathon_2021/data/Processed_files/state_\" + str(fileNum) + '.csv'\n",
    "  # df1.to_csv(filePath)\n",
    "  \n",
    "  return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the percentages in each column\n",
    "def agg(df):\n",
    "  # Create the list of numerical features\n",
    "  Numerical = ['PWGTP','AGEP','INTP','JWMNP','OIP','PAP','RETP','SEMP','SSIP','SSP','WAGP','WKHP','INDP','PERNP','PINCP','POVPIP']\n",
    "  cat = []\n",
    "\n",
    "  # Create list of categorical features\n",
    "  for i in df.columns:\n",
    "    if (i not in Numerical) & (i != 'YEAR') & (i != 'ST'):\n",
    "      cat.append(i)\n",
    "    \n",
    "    # Calculate mean of entire column for numerical features\n",
    "    elif (i in Numerical) & (i != 'YEAR'):\n",
    "      df[i] = df[i].mean()\n",
    "\n",
    "  # Calculate a proportion of the categorical columns\n",
    "  for j in cat:\n",
    "    df[j] = df[j].sum()/len(df)\n",
    "\n",
    "  # Remove duplicates\n",
    "  df2 = df.drop_duplicates()\n",
    "  \n",
    "  return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to iterate through all of the files and run each step of the process\n",
    "def allFilesProcess():\n",
    "  lstOfDfs = []\n",
    "  for i, file in enumerate(os.listdir()):\n",
    "    if ('.csv' in file) & (i > 40):\n",
    "      data = readData(file)\n",
    "      data2 = dropCols(data)\n",
    "      data3 = missingVals(data2)\n",
    "      data4 = oheCat(data3)\n",
    "      data5 = agg(data4)\n",
    "      \n",
    "      # Add the df to the list \n",
    "      lstOfDfs.append(data5)\n",
    "      print('Data ' + str(i) + ' has been added to the list')\n",
    "  \n",
    "  dfs = [df.reset_index() for df in lstOfDfs]\n",
    "  dfs_final = pd.concat(dfs, axis=0)\n",
    "  return dfs_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data 0 has been added to the list\n",
      "Data 1 has been added to the list\n",
      "Data 2 has been added to the list\n",
      "Data 3 has been added to the list\n",
      "Data 4 has been added to the list\n",
      "Data 5 has been added to the list\n",
      "Data 6 has been added to the list\n",
      "Data 7 has been added to the list\n",
      "Data 8 has been added to the list\n",
      "Data 9 has been added to the list\n",
      "Data 10 has been added to the list\n",
      "Data 12 has been added to the list\n",
      "Data 13 has been added to the list\n",
      "Data 14 has been added to the list\n",
      "Data 15 has been added to the list\n",
      "Data 16 has been added to the list\n",
      "Data 17 has been added to the list\n",
      "Data 18 has been added to the list\n",
      "Data 19 has been added to the list\n",
      "Data 20 has been added to the list\n",
      "CPU times: user 4min 6s, sys: 1min 21s, total: 5min 27s\n",
      "Wall time: 5min 40s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(20, 874)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "%%time\n",
    "valDf1 = allFilesProcess()\n",
    "valDf1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data 21 has been added to the list\n",
      "Data 22 has been added to the list\n",
      "Data 23 has been added to the list\n",
      "Data 24 has been added to the list\n",
      "Data 25 has been added to the list\n",
      "Data 26 has been added to the list\n",
      "Data 27 has been added to the list\n",
      "Data 28 has been added to the list\n",
      "Data 29 has been added to the list\n",
      "Data 30 has been added to the list\n",
      "Data 31 has been added to the list\n",
      "Data 32 has been added to the list\n",
      "Data 33 has been added to the list\n",
      "Data 34 has been added to the list\n",
      "Data 35 has been added to the list\n",
      "Data 36 has been added to the list\n",
      "Data 37 has been added to the list\n",
      "Data 38 has been added to the list\n",
      "Data 39 has been added to the list\n",
      "Data 40 has been added to the list\n",
      "CPU times: user 6min 25s, sys: 1min 28s, total: 7min 53s\n",
      "Wall time: 10min 5s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(20, 874)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "%%time\n",
    "valDf2 = allFilesProcess()\n",
    "valDf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data 41 has been added to the list\n",
      "Data 42 has been added to the list\n",
      "Data 43 has been added to the list\n",
      "Data 44 has been added to the list\n",
      "Data 45 has been added to the list\n",
      "Data 46 has been added to the list\n",
      "Data 47 has been added to the list\n",
      "Data 48 has been added to the list\n",
      "Data 49 has been added to the list\n",
      "Data 50 has been added to the list\n",
      "Data 51 has been added to the list\n",
      "Data 52 has been added to the list\n",
      "CPU times: user 4min 31s, sys: 1min 6s, total: 5min 37s\n",
      "Wall time: 6min 41s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(12, 873)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "%%time\n",
    "valDf3 = allFilesProcess()\n",
    "valDf3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine all of the files together\n",
    "def combineFiles(dfa, dfb, dfc):\n",
    "    dfAll = pd.concat([dfa, dfb, dfc], axis=0)\n",
    "\n",
    "    # Drop Puerto Rico from the dataset\n",
    "    dfAll1 = dfAll.loc[(dfAll['ST'] != 72)]\n",
    "\n",
    "    # Drop duplicates from the dataset\n",
    "    dfAll1.drop_duplicates(inplace=True)\n",
    "\n",
    "    return dfAll1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    index      PWGTP       AGEP         INTP      JWMNP         OIP  \\\n",
       "0   17890  21.279364  43.966185  3012.900290  25.997637  798.568979   \n",
       "0  135412  20.392778  41.432338  2336.570893  25.936327  673.028343   \n",
       "0   15733  19.883765  41.187754  2831.627256  18.868179  746.455196   \n",
       "0  235549  19.663560  42.089175  1924.474268  23.882141  600.256237   \n",
       "0   59204  20.036922  41.716085  1460.244227  22.248918  669.913370   \n",
       "\n",
       "         PAP         RETP         SEMP        SSIP  ...  OCCP_7830.0  \\\n",
       "0  40.212345  4863.615141  1879.121604  205.842786  ...          NaN   \n",
       "0  30.037991  2995.878181  1465.639596  234.462468  ...          NaN   \n",
       "0  30.794960  1389.390168  4822.054760  162.881145  ...     0.000127   \n",
       "0  37.568293  3040.171642  1439.858988  316.827275  ...     0.000034   \n",
       "0  26.070967  2159.919587  1628.948490  369.174875  ...     0.000100   \n",
       "\n",
       "   OCCP_1440.0  OCCP_3946.0  OCCP_7850.0  OCCP_8720.0  OCCP_2755.0  RACNUM_6  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN       NaN   \n",
       "0          NaN          NaN          NaN          NaN          NaN       NaN   \n",
       "0          NaN          NaN          NaN          NaN          NaN       NaN   \n",
       "0     0.000008     0.000034     0.000068     0.000272          NaN       NaN   \n",
       "0     0.000100     0.000100     0.000134     0.000167          NaN       NaN   \n",
       "\n",
       "   REGION_9  REGION_1  SFN_4.0  \n",
       "0       NaN       NaN      NaN  \n",
       "0       NaN       NaN      NaN  \n",
       "0       NaN       NaN      NaN  \n",
       "0       NaN       NaN      NaN  \n",
       "0       NaN       NaN      NaN  \n",
       "\n",
       "[5 rows x 876 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>PWGTP</th>\n      <th>AGEP</th>\n      <th>INTP</th>\n      <th>JWMNP</th>\n      <th>OIP</th>\n      <th>PAP</th>\n      <th>RETP</th>\n      <th>SEMP</th>\n      <th>SSIP</th>\n      <th>...</th>\n      <th>OCCP_7830.0</th>\n      <th>OCCP_1440.0</th>\n      <th>OCCP_3946.0</th>\n      <th>OCCP_7850.0</th>\n      <th>OCCP_8720.0</th>\n      <th>OCCP_2755.0</th>\n      <th>RACNUM_6</th>\n      <th>REGION_9</th>\n      <th>REGION_1</th>\n      <th>SFN_4.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17890</td>\n      <td>21.279364</td>\n      <td>43.966185</td>\n      <td>3012.900290</td>\n      <td>25.997637</td>\n      <td>798.568979</td>\n      <td>40.212345</td>\n      <td>4863.615141</td>\n      <td>1879.121604</td>\n      <td>205.842786</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>135412</td>\n      <td>20.392778</td>\n      <td>41.432338</td>\n      <td>2336.570893</td>\n      <td>25.936327</td>\n      <td>673.028343</td>\n      <td>30.037991</td>\n      <td>2995.878181</td>\n      <td>1465.639596</td>\n      <td>234.462468</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>15733</td>\n      <td>19.883765</td>\n      <td>41.187754</td>\n      <td>2831.627256</td>\n      <td>18.868179</td>\n      <td>746.455196</td>\n      <td>30.794960</td>\n      <td>1389.390168</td>\n      <td>4822.054760</td>\n      <td>162.881145</td>\n      <td>...</td>\n      <td>0.000127</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>235549</td>\n      <td>19.663560</td>\n      <td>42.089175</td>\n      <td>1924.474268</td>\n      <td>23.882141</td>\n      <td>600.256237</td>\n      <td>37.568293</td>\n      <td>3040.171642</td>\n      <td>1439.858988</td>\n      <td>316.827275</td>\n      <td>...</td>\n      <td>0.000034</td>\n      <td>0.000008</td>\n      <td>0.000034</td>\n      <td>0.000068</td>\n      <td>0.000272</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>59204</td>\n      <td>20.036922</td>\n      <td>41.716085</td>\n      <td>1460.244227</td>\n      <td>22.248918</td>\n      <td>669.913370</td>\n      <td>26.070967</td>\n      <td>2159.919587</td>\n      <td>1628.948490</td>\n      <td>369.174875</td>\n      <td>...</td>\n      <td>0.000100</td>\n      <td>0.000100</td>\n      <td>0.000100</td>\n      <td>0.000134</td>\n      <td>0.000167</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 876 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "completeDf = combineFiles(valDf1, valDf2, valDf3)\n",
    "completeDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(51, 876)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "completeDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine all of the additional datasets\n",
    "def addNewData():\n",
    "    # Read in all of the datasets\n",
    "    pmh = pd.read_csv('/Users/aakritigupta/Desktop/Hackathon 2021/Poor_ Mental_health_Days_2016.csv')\n",
    "    pmh.rename(columns={'STATE': 'State', 'VALUE':'pmh_Value'}, inplace=True)\n",
    "    pmh.drop(columns=['RANK'], inplace=True)\n",
    "    \n",
    "    ob = pd.read_csv('/Users/aakritigupta/Desktop/Hackathon 2021/Obesity_2016.csv')\n",
    "    ob['Value'] = ob['Value'].str.rstrip('%').astype('float') / 100.0\n",
    "    ob.rename(columns={'Value': 'ob_Value'}, inplace=True)\n",
    "    ob.drop(columns=['Rank'], inplace=True)\n",
    "    \n",
    "    isl = pd.read_csv('/Users/aakritigupta/Desktop/Hackathon 2021/Insufficient_sleep_2016.csv')\n",
    "    isl['Value'] = isl['Value'].str.rstrip('%').astype('float') / 100.0\n",
    "    isl.rename(columns={'Value': 'isl_Value'}, inplace=True)\n",
    "    isl.drop(columns=['Rank '], inplace=True)\n",
    "    \n",
    "    fmd = pd.read_csv('/Users/aakritigupta/Desktop/Hackathon 2021/Frequent Mental Distress_2016.csv')\n",
    "    fmd.rename(columns={'Value': 'fmd_Value'}, inplace=True)\n",
    "    fmd.drop(columns=['Rank '], inplace=True)\n",
    "    \n",
    "    air = pd.read_csv('/Users/aakritigupta/Desktop/Hackathon 2021/Air_Pollution_2016.csv')\n",
    "    air.rename(columns={'Value': 'air_Value'}, inplace=True)\n",
    "    air.drop(columns=['Rank'], inplace=True)\n",
    "\n",
    "    # Join the datasets on the State Name\n",
    "    lst = [pmh, ob, isl, fmd, air]\n",
    "    df_complete = reduce(lambda left, right: pd.merge(left, right, on='State'), lst)\n",
    "        \n",
    "    return df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          State  pmh_Value  ob_Value  isl_Value  fmd_Value  air_Value\n",
       "0  South Dakota        2.4     0.304      0.278      0.071        6.3\n",
       "1        Hawaii        2.9     0.227      0.440      0.088        7.0\n",
       "2     Minnesota        2.9     0.261      0.289      0.087        8.0\n",
       "3      Nebraska        2.9     0.314      0.300      0.089        7.3\n",
       "4          Iowa        3.2     0.321      0.301      0.095        8.6"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>pmh_Value</th>\n      <th>ob_Value</th>\n      <th>isl_Value</th>\n      <th>fmd_Value</th>\n      <th>air_Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>South Dakota</td>\n      <td>2.4</td>\n      <td>0.304</td>\n      <td>0.278</td>\n      <td>0.071</td>\n      <td>6.3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hawaii</td>\n      <td>2.9</td>\n      <td>0.227</td>\n      <td>0.440</td>\n      <td>0.088</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Minnesota</td>\n      <td>2.9</td>\n      <td>0.261</td>\n      <td>0.289</td>\n      <td>0.087</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Nebraska</td>\n      <td>2.9</td>\n      <td>0.314</td>\n      <td>0.300</td>\n      <td>0.089</td>\n      <td>7.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Iowa</td>\n      <td>3.2</td>\n      <td>0.321</td>\n      <td>0.301</td>\n      <td>0.095</td>\n      <td>8.6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "newData = addNewData()\n",
    "newData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add in the state initials to the dataset \n",
    "def addStInit(df, addDf):\n",
    "    abbr = pd.read_csv('/Users/aakritigupta/Desktop/Hackathon 2021/ST_Abbr_Lkp.csv', header=None)\n",
    "    abbr2 = abbr.rename(columns={0:'ST', 1:'State', 2:'LocationAbbr'})\n",
    "    abbr3 = abbr2[(abbr2['ST'] != 72) | (abbr2['ST'] != 11)]\n",
    "\n",
    "    # Join the abbreviations into the dataset\n",
    "    df1 = df.merge(abbr3, how='left', on='ST')\n",
    "\n",
    "    # Add the labels to the dataset\n",
    "    label = pd.read_csv('/Users/aakritigupta/Desktop/Hackathon 2021/cdc_data_17.csv')\n",
    "    label.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    df2 = df1.merge(label, how='left', on='LocationAbbr')\n",
    "\n",
    "    # Drop Puerto Rico from the dataset\n",
    "    df2.drop((df2[df2['LocationAbbr'] == 'PR'].index) | (df2[df2['LocationAbbr'] == 'DC'].index), inplace=True)\n",
    "\n",
    "    # Add in the additional data features to the dataset\n",
    "    df3 = df2.merge(addDf, how='left', on='State')\n",
    "\n",
    "    # Drop duplicates from the dataset\n",
    "    df4 = df3.drop_duplicates()\n",
    "\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    index      PWGTP       AGEP         INTP      JWMNP         OIP  \\\n",
       "0   17890  21.279364  43.966185  3012.900290  25.997637  798.568979   \n",
       "1  135412  20.392778  41.432338  2336.570893  25.936327  673.028343   \n",
       "2   15733  19.883765  41.187754  2831.627256  18.868179  746.455196   \n",
       "3  235549  19.663560  42.089175  1924.474268  23.882141  600.256237   \n",
       "4   59204  20.036922  41.716085  1460.244227  22.248918  669.913370   \n",
       "\n",
       "         PAP         RETP         SEMP        SSIP  ...  REGION_1  SFN_4.0  \\\n",
       "0  40.212345  4863.615141  1879.121604  205.842786  ...       NaN      NaN   \n",
       "1  30.037991  2995.878181  1465.639596  234.462468  ...       NaN      NaN   \n",
       "2  30.794960  1389.390168  4822.054760  162.881145  ...       NaN      NaN   \n",
       "3  37.568293  3040.171642  1439.858988  316.827275  ...       NaN      NaN   \n",
       "4  26.070967  2159.919587  1628.948490  369.174875  ...       NaN      NaN   \n",
       "\n",
       "          State  LocationAbbr  Label  pmh_Value  ob_Value  isl_Value  \\\n",
       "0      Delaware            DE    1.0        3.6     0.297      0.374   \n",
       "1       Arizona            AZ    0.0        3.8     0.284      0.327   \n",
       "2  North Dakota            ND    0.0        3.3     0.310      0.310   \n",
       "3          Ohio            OH    1.0        3.9     0.298      0.371   \n",
       "4      Arkansas            AR    1.0        4.7     0.345      0.364   \n",
       "\n",
       "   fmd_Value  air_Value  \n",
       "0      0.111        9.5  \n",
       "1      0.112        9.3  \n",
       "2      0.092        4.9  \n",
       "3      0.120       10.2  \n",
       "4      0.149        7.5  \n",
       "\n",
       "[5 rows x 884 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>PWGTP</th>\n      <th>AGEP</th>\n      <th>INTP</th>\n      <th>JWMNP</th>\n      <th>OIP</th>\n      <th>PAP</th>\n      <th>RETP</th>\n      <th>SEMP</th>\n      <th>SSIP</th>\n      <th>...</th>\n      <th>REGION_1</th>\n      <th>SFN_4.0</th>\n      <th>State</th>\n      <th>LocationAbbr</th>\n      <th>Label</th>\n      <th>pmh_Value</th>\n      <th>ob_Value</th>\n      <th>isl_Value</th>\n      <th>fmd_Value</th>\n      <th>air_Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17890</td>\n      <td>21.279364</td>\n      <td>43.966185</td>\n      <td>3012.900290</td>\n      <td>25.997637</td>\n      <td>798.568979</td>\n      <td>40.212345</td>\n      <td>4863.615141</td>\n      <td>1879.121604</td>\n      <td>205.842786</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Delaware</td>\n      <td>DE</td>\n      <td>1.0</td>\n      <td>3.6</td>\n      <td>0.297</td>\n      <td>0.374</td>\n      <td>0.111</td>\n      <td>9.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>135412</td>\n      <td>20.392778</td>\n      <td>41.432338</td>\n      <td>2336.570893</td>\n      <td>25.936327</td>\n      <td>673.028343</td>\n      <td>30.037991</td>\n      <td>2995.878181</td>\n      <td>1465.639596</td>\n      <td>234.462468</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Arizona</td>\n      <td>AZ</td>\n      <td>0.0</td>\n      <td>3.8</td>\n      <td>0.284</td>\n      <td>0.327</td>\n      <td>0.112</td>\n      <td>9.3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15733</td>\n      <td>19.883765</td>\n      <td>41.187754</td>\n      <td>2831.627256</td>\n      <td>18.868179</td>\n      <td>746.455196</td>\n      <td>30.794960</td>\n      <td>1389.390168</td>\n      <td>4822.054760</td>\n      <td>162.881145</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>North Dakota</td>\n      <td>ND</td>\n      <td>0.0</td>\n      <td>3.3</td>\n      <td>0.310</td>\n      <td>0.310</td>\n      <td>0.092</td>\n      <td>4.9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>235549</td>\n      <td>19.663560</td>\n      <td>42.089175</td>\n      <td>1924.474268</td>\n      <td>23.882141</td>\n      <td>600.256237</td>\n      <td>37.568293</td>\n      <td>3040.171642</td>\n      <td>1439.858988</td>\n      <td>316.827275</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Ohio</td>\n      <td>OH</td>\n      <td>1.0</td>\n      <td>3.9</td>\n      <td>0.298</td>\n      <td>0.371</td>\n      <td>0.120</td>\n      <td>10.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59204</td>\n      <td>20.036922</td>\n      <td>41.716085</td>\n      <td>1460.244227</td>\n      <td>22.248918</td>\n      <td>669.913370</td>\n      <td>26.070967</td>\n      <td>2159.919587</td>\n      <td>1628.948490</td>\n      <td>369.174875</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Arkansas</td>\n      <td>AR</td>\n      <td>1.0</td>\n      <td>4.7</td>\n      <td>0.345</td>\n      <td>0.364</td>\n      <td>0.149</td>\n      <td>7.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 884 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "completeDf2 = addStInit(completeDf, newData)\n",
    "completeDf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to impute missing values on aggregated dataset\n",
    "def missVals(df):\n",
    "    for i in df.columns:\n",
    "        missingVals = df[i].isnull().sum()\n",
    "        if missingVals > 0:\n",
    "            df[i].fillna(0.0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    index      PWGTP       AGEP         INTP      JWMNP         OIP  \\\n",
       "0   17890  21.279364  43.966185  3012.900290  25.997637  798.568979   \n",
       "1  135412  20.392778  41.432338  2336.570893  25.936327  673.028343   \n",
       "2   15733  19.883765  41.187754  2831.627256  18.868179  746.455196   \n",
       "3  235549  19.663560  42.089175  1924.474268  23.882141  600.256237   \n",
       "4   59204  20.036922  41.716085  1460.244227  22.248918  669.913370   \n",
       "\n",
       "         PAP         RETP         SEMP        SSIP  ...  REGION_1  SFN_4.0  \\\n",
       "0  40.212345  4863.615141  1879.121604  205.842786  ...       0.0      0.0   \n",
       "1  30.037991  2995.878181  1465.639596  234.462468  ...       0.0      0.0   \n",
       "2  30.794960  1389.390168  4822.054760  162.881145  ...       0.0      0.0   \n",
       "3  37.568293  3040.171642  1439.858988  316.827275  ...       0.0      0.0   \n",
       "4  26.070967  2159.919587  1628.948490  369.174875  ...       0.0      0.0   \n",
       "\n",
       "          State  LocationAbbr  Label  pmh_Value  ob_Value  isl_Value  \\\n",
       "0      Delaware            DE    1.0        3.6     0.297      0.374   \n",
       "1       Arizona            AZ    0.0        3.8     0.284      0.327   \n",
       "2  North Dakota            ND    0.0        3.3     0.310      0.310   \n",
       "3          Ohio            OH    1.0        3.9     0.298      0.371   \n",
       "4      Arkansas            AR    1.0        4.7     0.345      0.364   \n",
       "\n",
       "   fmd_Value  air_Value  \n",
       "0      0.111        9.5  \n",
       "1      0.112        9.3  \n",
       "2      0.092        4.9  \n",
       "3      0.120       10.2  \n",
       "4      0.149        7.5  \n",
       "\n",
       "[5 rows x 884 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>PWGTP</th>\n      <th>AGEP</th>\n      <th>INTP</th>\n      <th>JWMNP</th>\n      <th>OIP</th>\n      <th>PAP</th>\n      <th>RETP</th>\n      <th>SEMP</th>\n      <th>SSIP</th>\n      <th>...</th>\n      <th>REGION_1</th>\n      <th>SFN_4.0</th>\n      <th>State</th>\n      <th>LocationAbbr</th>\n      <th>Label</th>\n      <th>pmh_Value</th>\n      <th>ob_Value</th>\n      <th>isl_Value</th>\n      <th>fmd_Value</th>\n      <th>air_Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17890</td>\n      <td>21.279364</td>\n      <td>43.966185</td>\n      <td>3012.900290</td>\n      <td>25.997637</td>\n      <td>798.568979</td>\n      <td>40.212345</td>\n      <td>4863.615141</td>\n      <td>1879.121604</td>\n      <td>205.842786</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Delaware</td>\n      <td>DE</td>\n      <td>1.0</td>\n      <td>3.6</td>\n      <td>0.297</td>\n      <td>0.374</td>\n      <td>0.111</td>\n      <td>9.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>135412</td>\n      <td>20.392778</td>\n      <td>41.432338</td>\n      <td>2336.570893</td>\n      <td>25.936327</td>\n      <td>673.028343</td>\n      <td>30.037991</td>\n      <td>2995.878181</td>\n      <td>1465.639596</td>\n      <td>234.462468</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Arizona</td>\n      <td>AZ</td>\n      <td>0.0</td>\n      <td>3.8</td>\n      <td>0.284</td>\n      <td>0.327</td>\n      <td>0.112</td>\n      <td>9.3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15733</td>\n      <td>19.883765</td>\n      <td>41.187754</td>\n      <td>2831.627256</td>\n      <td>18.868179</td>\n      <td>746.455196</td>\n      <td>30.794960</td>\n      <td>1389.390168</td>\n      <td>4822.054760</td>\n      <td>162.881145</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>North Dakota</td>\n      <td>ND</td>\n      <td>0.0</td>\n      <td>3.3</td>\n      <td>0.310</td>\n      <td>0.310</td>\n      <td>0.092</td>\n      <td>4.9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>235549</td>\n      <td>19.663560</td>\n      <td>42.089175</td>\n      <td>1924.474268</td>\n      <td>23.882141</td>\n      <td>600.256237</td>\n      <td>37.568293</td>\n      <td>3040.171642</td>\n      <td>1439.858988</td>\n      <td>316.827275</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Ohio</td>\n      <td>OH</td>\n      <td>1.0</td>\n      <td>3.9</td>\n      <td>0.298</td>\n      <td>0.371</td>\n      <td>0.120</td>\n      <td>10.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>59204</td>\n      <td>20.036922</td>\n      <td>41.716085</td>\n      <td>1460.244227</td>\n      <td>22.248918</td>\n      <td>669.913370</td>\n      <td>26.070967</td>\n      <td>2159.919587</td>\n      <td>1628.948490</td>\n      <td>369.174875</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Arkansas</td>\n      <td>AR</td>\n      <td>1.0</td>\n      <td>4.7</td>\n      <td>0.345</td>\n      <td>0.364</td>\n      <td>0.149</td>\n      <td>7.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 884 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "valData3 = missVals(completeDf2)\n",
    "valData3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in the dataset\n",
    "def filterDf(df):\n",
    "    # Read in the dataset\n",
    "    fs = pd.read_csv('https://raw.githubusercontent.com/aagupta/MentalAid/main/stats_train.csv')\n",
    "    \n",
    "    # Drop the unnecessary columns\n",
    "    fs2 = fs.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Label_y'])\n",
    "    fsLabel = fs['Label_y']\n",
    "    state = df['State']\n",
    "\n",
    "    # Create a list of important features\n",
    "    fsCols = fs2.columns.tolist()\n",
    "\n",
    "    # Subset the dataframe\n",
    "    fs3 = df[fsCols]\n",
    "\n",
    "    # Write the dataset\n",
    "    fs3.to_csv('/Users/aakritigupta/Desktop/Hackathon 2021/MentSea/MentSea/Validation_2017.csv')\n",
    "\n",
    "    return (fs3, fsLabel, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   JWTRNS_8.0    HISP_2    HISP_4   HISP_21   HISP_24  OCCP_6240.0  \\\n",
       "0    0.000448  0.030792  0.001680  0.000000  0.001903     0.000448   \n",
       "1    0.001974  0.228045  0.001755  0.000395  0.009155     0.000936   \n",
       "2    0.000381  0.016006  0.000254  0.000000  0.001397     0.000508   \n",
       "3    0.000424  0.013944  0.000662  0.000323  0.001613     0.000314   \n",
       "4    0.000535  0.041433  0.000234  0.000100  0.002506     0.000635   \n",
       "\n",
       "   OCCP_9830.0   RAC1P_3   RAC1P_7   RAC1P_9  ...         OIP        PAP  \\\n",
       "0     0.001344  0.002239  0.000560  0.023738  ...  798.568979  40.212345   \n",
       "1     0.000892  0.073387  0.002091  0.037673  ...  673.028343  30.037991   \n",
       "2     0.001778  0.046621  0.000889  0.018293  ...  746.455196  30.794960   \n",
       "3     0.000204  0.001180  0.000458  0.023569  ...  600.256237  37.568293   \n",
       "4     0.000601  0.004979  0.002038  0.028234  ...  669.913370  26.070967   \n",
       "\n",
       "          RETP         SEMP        SSIP          SSP          WAGP  \\\n",
       "0  4863.615141  1879.121604  205.842786  4434.998681  29790.252440   \n",
       "1  2995.878181  1465.639596  234.462468  3658.658644  25751.907054   \n",
       "2  1389.390168  4822.054760  162.881145  3218.626322  27543.108276   \n",
       "3  3040.171642  1439.858988  316.827275  3420.941770  26213.031916   \n",
       "4  2159.919587  1628.948490  369.174875  3903.197562  20690.602051   \n",
       "\n",
       "          PERNP         PINCP      POVPIP  \n",
       "0  32049.812333  45025.512266  342.292926  \n",
       "1  27638.036299  37146.183171  300.314163  \n",
       "2  32747.248229  40744.938239  336.262899  \n",
       "3  28049.214735  36993.130397  312.937567  \n",
       "4  22667.264103  30908.071129  277.760004  \n",
       "\n",
       "[5 rows x 37 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>JWTRNS_8.0</th>\n      <th>HISP_2</th>\n      <th>HISP_4</th>\n      <th>HISP_21</th>\n      <th>HISP_24</th>\n      <th>OCCP_6240.0</th>\n      <th>OCCP_9830.0</th>\n      <th>RAC1P_3</th>\n      <th>RAC1P_7</th>\n      <th>RAC1P_9</th>\n      <th>...</th>\n      <th>OIP</th>\n      <th>PAP</th>\n      <th>RETP</th>\n      <th>SEMP</th>\n      <th>SSIP</th>\n      <th>SSP</th>\n      <th>WAGP</th>\n      <th>PERNP</th>\n      <th>PINCP</th>\n      <th>POVPIP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000448</td>\n      <td>0.030792</td>\n      <td>0.001680</td>\n      <td>0.000000</td>\n      <td>0.001903</td>\n      <td>0.000448</td>\n      <td>0.001344</td>\n      <td>0.002239</td>\n      <td>0.000560</td>\n      <td>0.023738</td>\n      <td>...</td>\n      <td>798.568979</td>\n      <td>40.212345</td>\n      <td>4863.615141</td>\n      <td>1879.121604</td>\n      <td>205.842786</td>\n      <td>4434.998681</td>\n      <td>29790.252440</td>\n      <td>32049.812333</td>\n      <td>45025.512266</td>\n      <td>342.292926</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.001974</td>\n      <td>0.228045</td>\n      <td>0.001755</td>\n      <td>0.000395</td>\n      <td>0.009155</td>\n      <td>0.000936</td>\n      <td>0.000892</td>\n      <td>0.073387</td>\n      <td>0.002091</td>\n      <td>0.037673</td>\n      <td>...</td>\n      <td>673.028343</td>\n      <td>30.037991</td>\n      <td>2995.878181</td>\n      <td>1465.639596</td>\n      <td>234.462468</td>\n      <td>3658.658644</td>\n      <td>25751.907054</td>\n      <td>27638.036299</td>\n      <td>37146.183171</td>\n      <td>300.314163</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000381</td>\n      <td>0.016006</td>\n      <td>0.000254</td>\n      <td>0.000000</td>\n      <td>0.001397</td>\n      <td>0.000508</td>\n      <td>0.001778</td>\n      <td>0.046621</td>\n      <td>0.000889</td>\n      <td>0.018293</td>\n      <td>...</td>\n      <td>746.455196</td>\n      <td>30.794960</td>\n      <td>1389.390168</td>\n      <td>4822.054760</td>\n      <td>162.881145</td>\n      <td>3218.626322</td>\n      <td>27543.108276</td>\n      <td>32747.248229</td>\n      <td>40744.938239</td>\n      <td>336.262899</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000424</td>\n      <td>0.013944</td>\n      <td>0.000662</td>\n      <td>0.000323</td>\n      <td>0.001613</td>\n      <td>0.000314</td>\n      <td>0.000204</td>\n      <td>0.001180</td>\n      <td>0.000458</td>\n      <td>0.023569</td>\n      <td>...</td>\n      <td>600.256237</td>\n      <td>37.568293</td>\n      <td>3040.171642</td>\n      <td>1439.858988</td>\n      <td>316.827275</td>\n      <td>3420.941770</td>\n      <td>26213.031916</td>\n      <td>28049.214735</td>\n      <td>36993.130397</td>\n      <td>312.937567</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000535</td>\n      <td>0.041433</td>\n      <td>0.000234</td>\n      <td>0.000100</td>\n      <td>0.002506</td>\n      <td>0.000635</td>\n      <td>0.000601</td>\n      <td>0.004979</td>\n      <td>0.002038</td>\n      <td>0.028234</td>\n      <td>...</td>\n      <td>669.913370</td>\n      <td>26.070967</td>\n      <td>2159.919587</td>\n      <td>1628.948490</td>\n      <td>369.174875</td>\n      <td>3903.197562</td>\n      <td>20690.602051</td>\n      <td>22667.264103</td>\n      <td>30908.071129</td>\n      <td>277.760004</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 37 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "(valData4, label, state) = filterDf(valData3)\n",
    "valData4.head()"
   ]
  },
  {
   "source": [
    "## Run code after predictions have been made"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add label back into the dataset to compare\n",
    "def addLabel(lst, stateLst):\n",
    "    # Read in the dataset\n",
    "    pred = pd.read_csv('/Users/aakritigupta/Desktop/Hackathon 2021/MentSea/MentSea/Predictions_2017.csv')\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    pred.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    # Join the label to the dataset and the state column\n",
    "    pred['Label'] = lst\n",
    "\n",
    "    # Add a condition if values don't match\n",
    "    pred['Match?'] = np.where(pred['Predictions'] != pred['Label'], 'False', 'True')\n",
    "\n",
    "    # Add in the states to the dataset\n",
    "    pred['State'] = state\n",
    "\n",
    "    # Write df to csv\n",
    "    pred.to_csv('/Users/aakritigupta/Desktop/Hackathon 2021/MentSea/MentSea/PredWLabel_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 12.8 ms, sys: 4.37 ms, total: 17.1 ms\nWall time: 19.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "addLabel(label, state)"
   ]
  }
 ]
}